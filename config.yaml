model:
    epochs: 100
    lr_g: 0.0002
    lr_d: 0.0002
    lr_decrease_epoch: 50
    lr_decrease_factor: 0.5

    lambda_l1_1: 100
    lambda_l1_2: 100
    lambda_perceptual: 100
    lambda_gan: 1
    lambda_patch: 10
#    lambda_texture: 1

    in_channels: 4
    out_channels: 3
    latent_channels: 48
    pad_type: 'zero'
    activation: 'elu'
    norm: 'bn'
    init_type: 'kaiming'
    init_gain: 0.02
    b1: 0.5
    b2: 0.999

data:
    train_image_root: 'data/COCOA/train2014'
    train_annot_file: 'data/COCOA/annotations/COCO_amodal_train2014.json'
    val_image_root: 'data/COCOA/val2014'
    val_annot_file: 'data/COCOA/annotations/COCO_amodal_val2014.json'
    input_size: 256

    enlarge_box: 2.
    eraser_setter:
        min_overlap: 0.4
        max_overlap: 0.7
        min_cut_ratio: 0.2
        max_cut_ratio: 0.7
    base_aug:
        flip: True
        shift: [-0.2, 0.2]
        scale: [0.8, 1.2]
    load_rgb: True
    batch_size: 8
    batch_size_val: 8
    workers: 2